0:00 | ANNOUNCER: Open content is provided under a creative
0:02 | commons license.
0:03 | Your support will help MIT OpenCourseWare continue to
0:06 | offer high-quality educational resources for free.
0:10 | To make a donation, or view additional materials from
0:13 | hundreds of MIT courses, visit MIT OpenCourseWare at
0:17 | ocw.mit.edu .
0:19 | PROFESSOR JOHN GUTTAG: All right.
0:23 | That said, let's continue, and if you remember last time, we
0:30 | ended up looking at this thing I called square roots bi.
0:35 | This was using something called a bisection method,
0:38 | which is related to something called binary search, which
0:42 | we'll see lots more of later, to find square roots.
0:47 | And the basic idea was that we had some sort of a line, and
0:53 | we knew the answer was somewhere between this point
0:57 | and this point.
1:00 | The line is totally ordered.
1:10 | And what that means, is that anything here is smaller than
1:16 | anything to its right.
1:19 | So the integers are totally ordered, the reals are totally
1:23 | ordered, lots of things are, the
1:25 | rationals are totally ordered.
1:28 | And that idea was, we make a guess in the middle, we test
1:32 | it so this is kind of a guess and check, and if the answer
1:37 | was too big, then we knew that we should be
1:41 | looking over here.
1:43 | If it was too small, we knew we should be looking over
1:45 | here, and then we would repeat.
1:50 | So this is very similar, this is a kind of recursive
1:53 | thinking we talked about earlier, where we take our
1:56 | problem and we make it smaller, we solve a smaller
1:59 | problem, et cetera.
2:02 | All right.
2:03 | So now, we've got it, I've got the code up for you.
2:10 | I want you to notice the specifications to start.
2:13 | We're assuming that x is greater than or equal to 0,
2:17 | and epsilon is strictly greater than 0, and we're
2:21 | going to return some value y such that y squared is within
2:26 | epsilon of x.
2:29 | I'd last time talked about the two assert statements.
2:34 | In some sense, strictly speaking they shouldn't be
2:36 | necessary, because the fact that my specification starts
2:42 | with an assumption, says, hey you, who might call square
2:46 | root, make sure that the things you call me with obey
2:51 | the assumption.
2:53 | On the other hand, as I said, never trust a programmer to do
2:56 | the right thing, so we're going to check it.
3:00 | And just in case the assumptions are not true,
3:02 | we're just going to stop dead in our tracks.
3:04 | All right.
3:08 | Then we're going to set low to-- low and high, and we're
3:12 | going to perform exactly the process I talked about.
3:18 | And along the way, I'm keeping track of how many iterations,
3:23 | at the end I'll print how many iterations I took, before I
3:26 | return the final guess.
3:28 | All right, let's test it.
3:32 | So one of the things I want you to observe here, is that
3:35 | instead of sitting there and typing away a bunch of test
3:38 | cases, I took the trouble to write a function, called test
3:43 | bi in this case.
3:44 | All right, so what that's doing, is it's taking the
3:49 | things I would normally type, and putting them in a
3:55 | function, which I can then call.
3:57 | Why is that better than typing them?
4:05 | Why was it worth creating a function to do this?
4:10 | Pardon?
4:11 | STUDENT:: [INAUDIBLE]
4:13 | PROFESSOR JOHN GUTTAG: Then I can I can use it again and
4:17 | again and again.
4:19 | Exactly.
4:24 | By putting it in a function, if I find a bug and I change
4:28 | my program, I can just run the function again.
4:33 | The beauty of this is, it keeps me from getting lazy,
4:40 | and not only testing my program and the thing that
4:43 | found the bug, but in all the things that used to work.
4:47 | We'll talk more about this later, but it often happens
4:51 | that when you change your program to solve one problem,
4:54 | you break it, and things that used to work don't work.
4:58 | And so what you want to do, and again we'll come back to
5:00 | this later in the term, is something
5:03 | called regression testing.
5:08 | This has nothing to do with linear regression.
5:13 | And that's basically trying to make sure our program has not
5:16 | regressed, as to say, gone backwards
5:19 | in how well it works.
5:21 | And so we always test it on everything.
5:24 | All right?
5:25 | So I've created this function, let's give it a shot and see
5:28 | what happens.
5:37 | We'll run test bi.
5:40 | Whoops!
5:42 | All right, well let's look at our answers.
5:46 | I first tested it on the square root of 4, and in one
5:51 | iteration it found 2.
5:53 | I like that answer.
5:56 | I then tested it on the square root of 9, and as I mentioned
5:59 | last time, I didn't find 3.
6:03 | I was not crushed.
6:05 | You know, I was not really disappointed, it found
6:08 | something close enough to 3 that I'm happy.
6:13 | All right.
6:13 | I tried it on 2, I surely didn't expect a precise and
6:18 | exact answer to that, but I got something, and if you
6:22 | square this, you'll find the answer kept pretty
6:24 | darn close to 2.
6:27 | I then tried it on 0.25 One quarter.
6:34 | And what happened was not what I wanted.
6:39 | As you'll see, it crashed.
6:44 | It didn't really crash, it found an assert statement.
6:50 | So if you look at the bottom of the function, you'll see
6:53 | that, in fact, I checked for that.
7:04 | I assert the counter is less than or equal to 0.
7:08 | I'm checking that I didn't leave my program because I
7:11 | didn't find an answer.
7:14 | Well, this is a good thing, it's better than my program
7:16 | running forever, but it's a bad thing because I don't have
7:21 | it the square root of 0.25.
7:25 | What went wrong here?
7:31 | Well, let's think about it for a second.
7:33 | You look like-- someone looks like they're
7:34 | dying to give an answer.
7:36 | No, you just scratching your head?
7:37 | All right.
7:39 | Remember, I said when we do a bisection method, we're
7:44 | assuming the answer lies somewhere between the lower
7:46 | bound and the upper bound.
7:51 | Well, what is the square root of a quarter?
7:56 | It is a half.
8:01 | Well, what-- where did I tell my program
8:06 | to look for an answer?
8:08 | Between 0 and x.
8:14 | So the problem was, the answer was over here somewhere, and
8:22 | so I'm never going to find it cleverly searching in this
8:25 | region, right?
8:28 | So the basic idea was fine, but I failed to satisfy the
8:34 | initial condition that the answer had to be between the
8:37 | lower bound and the upper bound.
8:40 | Right?
8:44 | And why did I do that?
8:45 | Because I forgot what happens when you look at fractions.
8:52 | So what should I do?
8:56 | Actually I lied, by the way, when I said the answer was
8:58 | over there.
8:59 | Where was the answer?
9:02 | Somebody?
9:05 | It was over here.
9:10 | Because the square root of a quarter is not smaller than a
9:15 | quarter, it's bigger than a quarter.
9:18 | Right?
9:18 | A half is strictly greater than a quarter.
9:27 | So it wasn't on the region.
9:29 | So how-- what's the fix?
9:31 | Should be a pretty simple fix, in fact we should be able to
9:33 | do it on the fly, here.
9:35 | What should I change?
9:40 | Do I need to change the lower bound?
9:42 | Is the square root ever going to be less than 0?
9:45 | Doesn't need to be, so, what should I do about the upper
9:49 | bound here?
9:52 | Oh, I could cheat and make, OK, the upper bound a half,
9:56 | but that wouldn't be very honest.
9:58 | What would be a good thing to do here?
10:05 | Pardon?
10:08 | I could square x, but maybe I should just do something
10:13 | pretty simple here.
10:16 | Suppose-- whoops.
10:19 | Suppose I make it the max of x and 1.
10:35 | Then if I'm looking for the square root of something less
10:38 | than 1, I know it will be in my region, right?
10:44 | All right, let's save this, and run it
10:47 | and see what happens.
11:04 | Sure enough, it worked and, did we get-- we got the right
11:08 | answer, 0.5 All right?
11:16 | And by the way, I checked all of my previous ones,
11:19 | and they work too.
11:25 | All right.
11:25 | Any questions about bisection search?
11:33 | One of the things I want you to notice here is the number
11:37 | iterations is certainly not constant.
11:42 | Yeah, when I will looked at 4, it was a nice number like 1, 9
11:46 | looked like it took me 18, 2 took me 14, if we try some big
11:54 | numbers it might take even longer.
12:00 | These numbers are small, but sometimes when we look at
12:03 | really harder problems, we got ourselves in a position where
12:08 | we do care about the number of iterations, and we care about
12:12 | something called the speed of convergence.
12:23 | Bisection methods were known to the ancient Greeks, and it
12:27 | is believed by many, even to the Babylonians.
12:32 | And as I mentioned last time, this was the state of the art
12:37 | until the 17th century.
12:41 | At which point, things got better.
12:45 | So, let's think about it, and let's think about what we're
12:51 | actually doing when we solve this.
12:54 | When we look for something like the square root of x,
12:59 | what we're really doing, is solving an equation.
13:06 | We're looking at the equation f of guess equals the guess
13:19 | squared minus x.
13:26 | Right, that's what that is equal to, and we're trying to
13:29 | solve the equation that f of guess equals 0.
13:39 | Looking for the root of this equation.
13:45 | So if we looked at it pictorially, what we've got
13:54 | here is, we're looking at f of x, I've plotted it here, and
14:02 | we're asking where it crosses the x axis.
14:08 | Sorry for the overloading of the word x.
14:12 | And I'm looking here at 16.
14:15 | Square root of 16, and my plot basically shows it crosses at
14:20 | 4 and-- well, I think that's minus 4.
14:23 | The perspective is tricky-- and so we're
14:28 | trying to find the roots.
14:32 | Now Isaac Newton and/or Joseph Raphson figured out how to do
14:37 | this kind of thing for all differentiable functions.
14:41 | Don't worry about what that means.
14:43 | The basic idea is, you take a guess, and you -- whoops --
14:50 | and you find the tangent of that guess.
14:56 | So let's say I guessed 3.
14:59 | I look for the tangent of the curve at 3.
15:04 | All right, so I've got the tangent, and then my next
15:07 | guess is going to be where the tangent crosses the x axis.
15:14 | So instead of dividing it in half, I'm using a different
15:18 | method to find the next guess.
15:24 | The utility of this relies upon the observation that,
15:29 | most of the time-- and I want to emphasize this, most of the
15:34 | time, that implies not all of the time-- the tangent line is
15:40 | a good approximation to the curve for
15:44 | values near the solution.
15:51 | And therefore, the x intercept of the tangent will be closer
15:56 | to the right answer than the current guess.
16:01 | Is that always true, by the way?
16:04 | Show me a place where that's not true, where the tangent
16:07 | line will be really bad.
16:12 | Yeah.
16:13 | Suppose I choose it right down there, I guess 0.
16:17 | Well, the tangent there will not even have an x intercept.
16:21 | So I'm really going to be dead in the water.
16:24 | This is the sort of thing that people who do numerical
16:27 | programming worry about all the time.
16:30 | And there are a lot of a little tricks they use to deal
16:32 | with that, they'll perturb it a little
16:34 | bit, things like that.
16:36 | You should not, at this point, be
16:37 | worrying about those things.
16:41 | This method, interestingly enough, is actually the method
16:45 | used in most hand calculators.
16:48 | So if you've got a calculator that has a square root button,
16:52 | it's actually in the calculator
16:53 | running Newton's method.
16:56 | Now I know you thought it was going to do that thing you
16:58 | learned in high school for finding square roots, which I
17:01 | never could quite understand, but no.
17:03 | It uses Newton's method to do it.
17:07 | So how do we find the intercept of the tangent, the
17:11 | x intercept?
17:13 | Well this is where derivatives come in.
17:17 | What we know is that the slope of the tangent is given by the
17:27 | first derivative of the function f at the
17:30 | point of the guess.
17:31 | So the slope of the guess is the first derivative.
17:36 | Right.
17:36 | Which dy over dx.
17:41 | Change in y divided by change in x.
17:45 | So we can use some algebra, which I won't go through here,
17:50 | and what we would find is that for square root, the
17:54 | derivative, written f prime of the i'th guess is equal to two
18:05 | times the i'th guess.
18:07 | Well, should have left myself a little more room, sorry
18:10 | about that.
18:15 | All right?
18:18 | You could work this out.
18:20 | Right?
18:20 | The derivative of the square root is not
18:22 | a complicated thing.
18:26 | Therefore, and here's the key thing we need to keep in mind,
18:35 | we'll know that we can choose guess i plus 1 to be equal to
18:46 | the old guess, guess i, minus whatever the value is of the
18:53 | new guess-- of the old rather, the old guess-- divided by
19:03 | twice the old guess.
19:14 | All right, again this is straightforward kind of
19:17 | algebraic manipulations to get here.
19:20 | So let's look at an example.
19:22 | Suppose we start looking for the square root of 16
19:25 | with the guess 3.
19:30 | What's the value of the function f of 3?
19:37 | Well, it's going to be, we looked at our function there,
19:41 | guess squared, 3 times 3 is 9 I think, minus 16, that's what
19:54 | x is in this case, which equals minus 7.
20:02 | That being the case, what's my next guess?
20:13 | Well I start with my old guess, 3, minus f of my old
20:22 | guess, which is minus 7, divided by twice my old guess,
20:33 | which is 6, minus the minus, and I get as my new guess
20:42 | 4.1666 or thereabouts.
20:51 | So you can see I've missed, but I am closer.
20:57 | And then I would reiterate this process using that as
21:03 | guess i, and do it again.
21:08 | One way to think about this intuitively, if the derivative
21:12 | is very large, the function is changing quickly, and
21:19 | therefore we want to take small steps.
21:21 | All right.
21:23 | If the derivative is small, it's not changing, maybe want
21:28 | to take a larger step, but let's not worry
21:31 | about that, all right?
21:34 | Does this method work all the time?
21:37 | Well, we already saw no, if my initial guess is zero, I don't
21:42 | get anywhere.
21:44 | In fact, my program crashes because I end up trying to
21:46 | divide by zero, a really bad thing.
21:49 | Hint: if you implement Newton's method, do not make
21:53 | your first guess zero.
21:57 | All right, so let's look at the code for that.
22:08 | All right so-- yeah, how do I get to the code for that?
22:13 | That's interesting.
22:25 | All right.
22:30 | So we have that square root NR.
22:32 | NR for Newton Raphson.
22:36 | First thing I want you to observe is its specification
22:40 | is identical to the specification
22:43 | of square root bi.
22:48 | What that's telling me is that if you're a user of this, you
22:54 | don't care how it's implemented, you
22:56 | care what it does.
23:00 | And therefore, it's fine that the specifications are
23:03 | identical, in fact it's a good thing, so that means if
23:06 | someday Professor Grimson invents something that's
23:09 | better than Newton Raphson, we can all re-implement our
23:12 | square root functions and none of the programs that use it
23:16 | will have to change, as long as the
23:18 | specification is the same.
23:24 | All right, so, not much to see about this.
23:28 | As I said, the specifications is the same, same assertions,
23:33 | and the-- it's basically the same program as the one we
23:35 | were just looking at, but I'm starting with a different
23:43 | guess, in this case x over 2, well I'm going to, couple of
23:48 | different guesses we can start with, we can experiment with
23:52 | different guesses and see whether we get the same
23:54 | answer, and in fact, if we did, we would see we didn't
23:57 | get this, we got different answers, but correct answers.
24:02 | Actually now, we'll just comment that out.
24:09 | I'm going to compute the difference, just as I did on
24:13 | the board, and off we'll go.
24:17 | All right.
24:18 | Now, let's try and compare these things.
24:23 | And what we're going to look at is another procedure, you
24:30 | have the code for these things on your handout so we won't
24:33 | worry, don't need to show you the code, but let's look at
24:38 | how we're going to test it.
24:40 | I'm doing a little trick by the way, I'm using raw input
24:45 | in my function here, as a just a way to stop the display.
24:49 | This way I can torture you between tests
24:52 | by asking you questions.
24:54 | Making it stop.
24:57 | All right, so, we'll try some things.
24:59 | We'll see what it does.
25:06 | Starting with that, well, let's look at some of the
25:09 | things it will do.
25:12 | Yeah, I'll save it..
25:23 | It's a little bit annoying, but it makes the font bigger.
25:34 | All right, so we've tested it, and we haven't tested it yet,
25:39 | we have tested it but, we haven't seen it, well, you
25:46 | know what I'm going to do?
25:47 | I'm going to tort--
25:48 | I'm going to make the font smaller so we can see more.
25:51 | Sorry about this.
25:52 | Those of you in the back, feel free to move forward.
26:04 | All right.
26:08 | So we've got it, now let's test it.
26:12 | So we're going to do here, we're going
26:13 | to run compare methods.
26:20 | Well we're seeing this famous computers are no damn good.
26:32 | All right.
26:34 | So we're going to try it on 2, and at least we'll notice for
26:37 | 2, that the bisection method took eight iterations, the
26:43 | Newton Raphson only took three,
26:46 | so it was more efficient.
26:49 | They came up with slightly different answers, but both
26:52 | answers are within .01 which is what I gave it here for
26:56 | epsilon, so we're OK.
26:59 | So even though they have different answers, they both
27:02 | satisfy the same specification,
27:05 | so we have no problem.
27:09 | All right?
27:11 | Try it again, just for fun.
27:17 | I gave it here a different epsilon, and you'll note, we
27:21 | get different answers.
27:26 | Again, that's OK.
27:29 | Notice here, when I asked for a more precise answer,
27:35 | bisection took a lot more iterations, but Newton Raphson
27:43 | took only one extra iteration to get that extra precision in
27:47 | the answer.
27:49 | So we're sort of getting the notion that Newton Raphson
27:54 | maybe is considerably better on harder problems. Which, by
27:59 | the way, it is.
28:03 | We'll make it an even harder problem, by making it looking
28:08 | an even smaller epsilon, and again, what you'll see is,
28:13 | Newton Raphson just crept up by one, didn't take it long,
28:19 | and got the better answer, where bisection
28:22 | gets worse and worse.
28:23 | So as you can see, as we escalate the problem
28:26 | difficulty, the difference between the good method and
28:30 | the not quite as good method gets bigger
28:33 | and bigger and bigger.
28:35 | That's an important observation, and as we get to
28:38 | the part of the course, we talk about computational
28:41 | complexity, you'll see that what we really care about is
28:45 | not how efficient the program is on easy problems, but how
28:49 | efficient it is on hard
28:51 | problems. All right.
28:57 | Look at another example.
29:00 | All right, here I gave it a big number, 123456789.
29:07 | And again, I don't want to bore you, but you can see
29:11 | what's going on here with this trend.
29:19 | So here's an interesting question.
29:27 | You may notice that it's always printing out the same
29:30 | number of digits.
29:36 | Why should this be?
29:39 | If you look at it here, what's going on?
29:48 | Something very peculiar is happening here.
29:55 | We're looking at it, and we're getting some funny answers.
30:04 | This gets back to what I talked about before, about
30:08 | some of the precision of floating point numbers.
30:11 | And the thing I'm trying to drive home to you here is
30:20 | perhaps the most important lesson we'll
30:23 | talk about all semester.
30:33 | Which is, answers can be wrong.
30:49 | People tend to think, because the computer says it's so, it
30:52 | must be so.
30:53 | That the computer is-- speaks for God.
30:58 | And therefore it's infallible.
31:00 | Maybe it speaks for the Pope.
31:01 | It speaks for something that's infallible.
31:03 | But in fact, it is not.
31:06 | And so, something I find myself repeating over and over
31:10 | again to myself, to my graduate students, is, when
31:15 | you get an answer from the computer, always ask yourself,
31:19 | why do I believe it?
31:21 | Do I think it's the right answer?
31:26 | Because it isn't necessarily.
31:31 | So if we look at what we've got here, we've got something
31:34 | rather peculiar, right?
31:36 | What's peculiar about what this computer is now
31:38 | printing for us?
31:47 | Why should I be really suspicious about what I see in
31:50 | the screen here?
31:51 | STUDENT: [INAUDIBLE]
31:56 | PROFESSOR JOHN GUTTAG: Well, not only is it different, it's
31:58 | really different, right?
32:00 | If it were just a little bit different, I could say, all
32:02 | right, I have a different approximation.
32:05 | But when it's this different, something is wrong.
32:10 | Right?
32:12 | We'll, later in the term when we get to more detailed
32:17 | numerical things, look at what's wrong.
32:20 | You can run into issues of things like overflow,
32:23 | underflow, with floating point numbers, and when you see a
32:26 | whole bunches of ones, it's particularly a good time to be
32:30 | suspicious.
32:33 | Anyway the only point I'm making here is, paranoia is a
32:39 | healthy human trait.
32:43 | All right.
32:44 | We can look at some other things which will work better.
32:50 | And we'll now move on.
32:52 | OK.
32:53 | So we've looked at how to solve square root we've,
32:56 | looked at two problems, I've tried to instill in you this
32:59 | sense of paranoia which is so valuable, and now we're going
33:03 | to pull back and return to something much simpler than
33:08 | numbers, and that's Python.
33:11 | All right?
33:12 | Numbers are hard.
33:13 | That's why we teach whole semesters worth of courses in
33:16 | number theory.
33:17 | Python it's easy, which is why we do it in about four weeks.
33:24 | All right.
33:25 | I want to return to some non-scalar types.
33:34 | So we've been looking, the last couple of lectures, at
33:39 | floating point numbers and integers.
33:43 | We've looked so far really at two non-scalar types.
33:47 | And those were tuples written with parentheses, and strings.
34:02 | The key thing about both of them is
34:05 | that they were immutable.
34:11 | And I responded to at least one email about this issue,
34:15 | someone quite correctly said tuple are immutable, how can I
34:20 | change one?
34:21 | My answer is, you can't change one, but you can create a new
34:25 | one that is almost like the old one but different in a
34:28 | little bit.
34:31 | Well now we're going to talk about some mutable types.
34:38 | Things you can change.
34:42 | And we're going to start with one that you, many of you,
34:46 | have already bumped into, perhaps by
34:48 | accident, which are lists.
34:53 | Lists differ from strings in two ways; one way is that it's
34:58 | mutable, the other way is that the values need not be
35:03 | characters.
35:05 | They can be numbers, they can be characters, they can be
35:08 | strings, they can even be other lists.
35:13 | So let's look at some examples here.
35:18 | What we'll do, is we'll work on two boards at once.
35:27 | So I could write a statement like, techs, a variable, is
35:36 | equal to the list, written with the square brace, not a
35:39 | parenthesis, MIT, Cal Tech, closed brace.
35:55 | What that basically does, is it takes the variable techs,
36:03 | and it now makes it point to a list with two items in it.
36:15 | One is the string MIT and one is the string Cal Tech.
36:25 | So let's look at it.
36:29 | And we'll now run another little test program, show
36:37 | lists, and I printed it, and it prints the
36:41 | list MIT, Cal Tech.
36:49 | Now suppose I introduce a new variable, we'll call it ivys,
36:55 | and we say that is equal to the list Harvard, Yale, Brown.
37:07 | Three of the ivy league colleges.
37:11 | What that does is, I have a new variable, ivys, and it's
37:16 | now pointing to another, what we call object, in Python and
37:24 | Java, and many other languages, think of these
37:28 | things that are sitting there in memory
37:29 | somewhere as objects.
37:31 | And I won't write it all out, I'll just write it's got
37:34 | Harvard as one in it, and then it's got Yale, and
37:39 | then it's got Brown.
37:43 | And I can now print ivys.
37:49 | And it sure enough prints what we expected it to print.
37:55 | Now, let's say I have univs, for universities, equals the
38:03 | empty list. That would create something over here called
38:11 | univs, another variable, and it will point to the list, an
38:16 | object that contains nothing in it.
38:19 | This is not the same as none.
38:22 | It's it does have a value, it just happens to be the list
38:25 | that has nothing in it.
38:29 | And the next thing I'm going to write is
38:33 | univs dot append tex.
38:50 | What is this going to do?
38:54 | It's going to take this list and add to it something else.
39:03 | Let's look at the code.
39:17 | I'm going to print it, and let's see what it prints.
39:21 | It's kind of interesting.
39:24 | Whoops.
39:25 | Why did it do that?
39:27 | That's not what I expected.
39:36 | It's going to print that.
39:37 | The reason it printed that is I accidentally had my finger
39:39 | on the control key, which said print the last thing you had.
39:46 | Why does it start with square braced square brace?
39:56 | I take it-- yes, go ahead.
39:58 | STUDENT: So you're adding a list to a list?
40:01 | PROFESSOR JOHN GUTTAG: So I'm adding a list to a list. What
40:04 | have I-- what I've appended to the empty list is not the
40:10 | elements MIT and Cal Tech but the list that
40:15 | contains those elements.
40:21 | So I've appended this whole object.
40:24 | Since that object is itself a list, what I get
40:28 | is a list of lists.
40:37 | Now I should mention this notation here append is what
40:49 | is in Python called a method.
40:54 | Now we'll hear lots more about methods when we get to classes
40:58 | and inheritance, but really, a method is just a fancy word
41:03 | for a function with different syntax.
41:08 | Think of this as a function that takes two arguments, the
41:13 | first of which is univs and the second of which is techs.
41:21 | And this is just a different syntax for writing that
41:25 | function call.
41:27 | Later in the term, we'll see why we have this syntax and
41:33 | why it wasn't just a totally arbitrary brain-dead decision
41:37 | by the designers of Python, and many languages before
41:41 | Python, but in fact is a pretty sensible thing.
41:45 | But for now, think of this as just another way to write a
41:48 | function call.
41:54 | All right, people with me so far?
42:00 | Now let's say we wanted as the next thing we'll do, is we're
42:08 | going to append the ivys to univ. Stick
42:15 | another list on it.
42:18 | All right.
42:20 | So we'll do that, and now we get MIT, Cal Tech, followed by
42:29 | that list followed by the list Harvard, Yale, Brown.
42:32 | So now we have a list containing two lists.
42:41 | What are we going to try next?
42:45 | Well just to see what we know what we're doing, let's look
42:49 | at this code here.
42:56 | I've written a little for loop, which is going to
42:59 | iterate over all of the elements in the list. So
43:03 | remember, before we wrote things like for i in range 10,
43:10 | which iterated over a list or tuple of numbers, here you can
43:17 | iterate over any list, and so we're going to just going to
43:20 | take the list called univs and iterate over it.
43:26 | So the first thing we'll do is, we'll print the element,
43:30 | in this case it will be a list, right?
43:32 | Because it's a list with two lists in it.
43:35 | Then the next thing in the loop, we're going to enter a
43:38 | nested loop, and say for every college in the list e, we're
43:46 | going to print the name of the college.
43:51 | So now if we look what we get-- do you not want to try
43:59 | and execute that?-- it'll first print the list
44:07 | containing MIT and Cal Tech, and then separately the
44:11 | strings MIT and Cal Tech, and then the list containing
44:14 | Harvard, Yale, and Brown, and then the strings Harvard,
44:18 | Yale, and Brown.
44:21 | So we're beginning to see this is a pretty powerful notion,
44:25 | these lists, and that we can do a lot of
44:27 | interesting things with them.
44:31 | Suppose I don't want all of this structure, and I want to
44:37 | do what's called flattening the list. Well I can do that
44:51 | by, instead of using the method append, use the
44:56 | concatenation operator.
45:00 | So I can concatenate techs plus ivys and assign that
45:06 | result to univs, and then when I print it you'll notice I
45:13 | just get a list of five strings.
45:19 | So plus and append do very different things.
45:24 | Append sticks the list on the end of the list, append
45:30 | flattens it, one level of course.
45:32 | If I had lists of lists of lists, then it would only take
45:36 | out the first level of it.
45:41 | OK, very quiet here.
45:45 | Any questions about any of this?
45:49 | All right.
45:49 | Because we're about to get to the hard part Sigh.
45:53 | All right.
45:54 | Let's look at the-- well, suppose I want to, quite
45:58 | understandably, eliminate Harvard.
46:00 | All right, I then get down here, where I'm
46:05 | going to remove it.
46:09 | So this is again another method, this is remove, takes
46:13 | two arguments, the first is ivys, the second
46:16 | is the string Harvard.
46:21 | It's going to search through the list until the first time
46:25 | it finds Harvard and then it's going to yank it away.
46:39 | So what happened here?
46:42 | Did I jump to the wrong place?
46:45 | STUDENT: You hit two returns.
46:45 | PROFESSOR JOHN GUTTAG: I hit two returns.
46:46 | Pardon?
46:46 | STUDENT: You hit two returns.
46:47 | One was at
46:47 | STUDENT: Pardo
46:53 | PROFESSOR JOHN GUTTAG: This one.
46:54 | STUDENT: No, up one.
46:55 | PROFESSOR JOHN GUTTAG: Up one.
46:56 | STUDENT: Right.
46:57 | PROFESSOR JOHN GUTTAG: But why is Harvard there?
46:57 | STUDENT: I'm sorry, I didn't write it down.
47:00 | PROFESSOR JOHN GUTTAG: Let's look at it again.
47:00 | All right, it's time to interrupt the world, and we'll
47:04 | just type into the shell.
47:06 | Let's see what we get here.
47:16 | All right, so let's just see what we got, we'll print
47:18 | univs. Nope, not defined.
47:22 | All right, well let's do a list equals, and we'll put
47:26 | some interesting things in it, we'll put a number in it,
47:29 | because we can put a number, we'll put MIT in it, because
47:33 | we can put strings, we'll put another number in it, 3.3,
47:38 | because we can put floating points, we can put all sorts
47:42 | of things in this list. We can put a list in the list again,
47:45 | as we've seen before.
47:47 | So let's put the list containing the string a, and
47:53 | I'll print out, so now we see something pretty interesting
47:57 | about a list, that we can mix up all sorts of things in it,
48:03 | and that's OK.
48:06 | You'll notice I have the string with the number 1, a
48:08 | string with MIT, and then it just a plain old number, not a
48:12 | string, again it didn't quite give me 3.3 for reasons we've
48:16 | talked before, and now it in the list a.
48:21 | So, suppose I want to remove something.
48:27 | What should we try and remove from this list?
48:32 | Anybody want to vote?
48:37 | Pardon?
48:38 | All right, someone wants to remove MIT.
48:42 | Sad but true.
48:45 | Now what do we get if we print l?
48:47 | MIT is gone.
48:51 | How do I talk about the different pieces of l?
48:54 | Well I can do this. l sub 0-- whoops-- will give me the
49:04 | first element of the list, just as we could do with
49:09 | strings, and I can look at l sub minus 1 to get the last
49:13 | element of the list, so I can do all the strings, all the
49:17 | things that I could do with strings.
49:20 | It's extremely powerful, but what we
49:23 | haven't seen yet is mutation.
49:29 | Well, we have seen mutation, right?
49:32 | Because notice that what remove did, it was it actually
49:36 | changed the list. Didn't create a new list. The old l
49:42 | is still there, but it's different than it used to be.
49:47 | So this is very different from what we did with slicing,
49:51 | where we got a new copy of something.
49:54 | Here we took the old one and we just changed it.
49:59 | On Thursday, we'll look at why that allows you to do lots of
50:05 | things more conveniently than you can do without mutation.
