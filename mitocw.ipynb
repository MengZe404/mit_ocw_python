{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import random\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# List of user agents to rotate\n",
    "USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.104 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\",\n",
    "    # Add more user agents as needed\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get HTML content from a URL\n",
    "def get_html_content(url):\n",
    "    headers = {'User-Agent': random.choice(USER_AGENTS)}  # Randomly select user agent\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.content\n",
    "        else:\n",
    "            print(f\"Failed to fetch URL: {url}. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract timestamp and content from HTML\n",
    "def extract_course_content(url):\n",
    "    name = re.search(r'courses/(.*?)/', url).group(1)\n",
    "    \n",
    "    html_content = get_html_content(url)\n",
    "    if html_content:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        videos = soup.find_all('a', class_='resource-thumbnail')\n",
    "        titles = soup.find_all('a', class_='resource-list-title')\n",
    "        \n",
    "        videos_txt = f\"./{name}/{'videos_'}{name}.txt\"\n",
    "        titles_txt = f\"./{name}/{'titles_'}{name}.txt\"\n",
    "        \n",
    "        with open(videos_txt, 'w') as txt_file:\n",
    "            for i in range(0, len(videos)):\n",
    "                txt_file.write(f\"{videos[i]['href']}\\n\")\n",
    "                \n",
    "        with open(titles_txt, 'w') as txt_file:\n",
    "            for i in range(0, len(titles)):\n",
    "                txt_file.write(f\"{'https://ocw.mit.edu/'}{titles[i]['href']}\\n\")\n",
    "                \n",
    "        print(f\"Data extracted and written successfully\")\n",
    "    else:\n",
    "        print(\"Failed to extract HTML content.\")\n",
    "        \n",
    "    return (f\"./{name}/{'videos_'}{name}.txt\", f\"./{name}/{'titles_'}{name}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_transcript(url, location):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 10_3 like Mac OS X) AppleWebKit/602.1.50 (KHTML, like Gecko) CriOS/56.0.2924.75 Mobile/14E5239e Safari/602.1')\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    \n",
    "    driver.find_element(By.CLASS_NAME, value=\"tab-title-section\").click()\n",
    "\n",
    "    # Wait for some time for the page to load or elements to appear\n",
    "    time.sleep(5)  # Wait for 5 seconds (adjust as needed)\n",
    "\n",
    "    # Get HTML content after operations have been performed\n",
    "    html_content = driver.page_source\n",
    "\n",
    "    # # Extract timestamp and content from HTML\n",
    "    # extract_timestamp_content(html_content, url)\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    # Use regular expression to extract the desired part\n",
    "    name = url.split(\"/\")[-2]\n",
    "    \n",
    "    if html_content:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        transcript_lines = soup.find_all('div', class_='transcript-line')\n",
    "        filename = f\"./{location}/{'transcripts'}/{name}.txt\"\n",
    "        with open(filename, 'w') as txt_file:\n",
    "            for line in transcript_lines:\n",
    "                timestamp = line.find('span', class_='transcript-timestamp').text.strip()\n",
    "                content = line.find('span', class_='transcript-text').text.strip()\n",
    "                content = \" \".join(content.split(\"\\n\"))  # Remove newline characters\n",
    "                txt_file.write(f\"{timestamp} | {content}\\n\")\n",
    "        print(f\"Data extracted and written to {filename}\")\n",
    "    else:\n",
    "        print(\"Failed to extract HTML content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created successfully!\n",
      "Data extracted and written successfully\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-1.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-2.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-3.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-4.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-5.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-6.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-7.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-8.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-9.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-10.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-11.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-12.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-13.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-14.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-15.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-16.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-17.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-18.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-19.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-20.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-21.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-22.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-23.txt\n",
      "Data extracted and written to ./6-00-introduction-to-computer-science-and-programming-fall-2008/transcripts/lecture-24.txt\n"
     ]
    }
   ],
   "source": [
    "def agent(course_url):\n",
    "    course_name = re.search(r'courses/(.*?)/', course_url).group(1)\n",
    "    \n",
    "        # Check if the directory already exists\n",
    "    if not os.path.exists(course_name):\n",
    "        # Create the directory\n",
    "        os.makedirs(course_name)\n",
    "        os.makedirs(f\"{course_name}/{'transcripts'}\")\n",
    "        os.makedirs(f\"{course_name}/{'videos'}\")\n",
    "        print(\"Directory created successfully!\")\n",
    "    else:\n",
    "        print(\"Directory already exists!\")\n",
    "        \n",
    "    raw_data = extract_course_content(course_url)\n",
    "    \n",
    "    videos = []\n",
    "    contents = []\n",
    "    \n",
    "    with open(raw_data[0], 'r') as file:\n",
    "        for line in file:\n",
    "            videos.append(line.strip())\n",
    "    \n",
    "    with open(raw_data[1], 'r') as file:\n",
    "        for line in file:\n",
    "            contents.append(line.strip())\n",
    "            \n",
    "    for i in range(0, len(videos)):\n",
    "        get_video_transcript(contents[i], course_name) \n",
    "        # name = contents[i].split(\"/\")[-2]\n",
    "        # urllib.request.urlretrieve(videos[i], f\"{course_name}/{'videos'}/{name}.mp4\") \n",
    "\n",
    "course_url = \"https://ocw.mit.edu/courses/6-00-introduction-to-computer-science-and-programming-fall-2008/resources/lecture-videos/\"\n",
    "agent(course_url)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
